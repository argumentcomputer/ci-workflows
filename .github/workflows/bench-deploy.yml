# Intended to run on the `push` trigger
# Pre-requisites
# - `gh-pages` branch with Pages deployment set up
# - Ideally some HTML to link to the reports, e.g. https://lurk-lab.github.io/ci-lab/
# - Self-hosted runner attached to the caller repo with `gpu-bench` and `gh-pages` tags
# - `justfile` with a `gpu-bench-ci` recipe that outputs `<bench-name>-<short-commit-hash>.json`
#
# The core file structure is a `benchmarks/history` directory on the `gh-pages` branch that contains:
# - Historical data `.tar.gz` archives, one for each commit or workflow run, which contain the Criterion benchmark results
#   and `Cargo.lock` for the given commit.
# - Historical data in `plot-data.json`, which contains only the relevant metadata and average benchmark result for each of
#   the saved benchmarks. This file is persistent and append-only, and if it's not found then it is re-created using each of
#   the `tar.gz` archives
# - `.png` plot images, created on each run using `plot-data.json`
# - HTML to render the images.
#
# This structure is all created/deployed by the workflow after running the benchmarks,
# with the only prerequisite being an existing `gh-pages` branch deployed via GitHub Pages.
# See https://github.com/lurk-lab/ci-lab/tree/gh-pages as an example of the deployed plots
name: Deploy GPU benchmark from default branch

on:
  workflow_call:
    inputs:
      # Leave as default for lurk-rs, input `ARECIBO` for arecibo
      env-prefix:
        required: false
        default: 'LURK'
        type: string
      # List of prerequisite Ubuntu packages, separated by whitespace
      packages:
        required: false
        type: string

jobs:
  benchmark:
    name: Bench and deploy
    runs-on: [self-hosted, gpu-bench, gh-pages]
    steps:
      - uses: actions/checkout@v4
        with:
          repository: lurk-lab/ci-workflows
      - uses: ./.github/actions/gpu-setup
        with:
          gpu-framework: 'cuda'
      - uses: ./.github/actions/ci-env
      - uses: ./.github/actions/install-deps
        with:
          packages: "${{ inputs.packages }} pkg-config libfontconfig1-dev"
      # Install deps
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - uses: Swatinem/rust-cache@v2
      - uses: taiki-e/install-action@v2
        with:
          tool: just@1.22.0
      # Run benchmarks and deploy
      - name: Get old benchmarks
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          path: gh-pages
      - name: Install criterion
        run: cargo install cargo-criterion
      - name: Copy old benchmarks locally for comparison
        run: |
          mkdir -p target gh-pages/benchmarks/criterion
          cp -r gh-pages/benchmarks/criterion target
      # Make sure to set repo-specific env vars in the `justfile`/`bench.env`, e.g. `LURK_RC`
      - name: Set env vars
        run: |
          echo "COMMIT=$(git rev-parse --short HEAD)" | tee -a $GITHUB_ENV
          echo "${{ inputs.env-prefix }}_BENCH_OUTPUT=gh-pages" | tee -a $GITHUB_ENV
      - name: Run benchmarks
        run: |
          just gpu-bench-ci fibonacci
          mv fibonacci-${{ env.COMMIT }}.json ${{ github.workspace }}
        working-directory: ${{ github.workspace }}/benches
      - uses: actions/checkout@v4
        with:
          repository: lurk-lab/ci-workflows
          ref: bench-deploy
          path: ci-workflows
      # If no plot data found, unzip all historical bench results to re-create the plots
      - name: Check for existing plot data
        run: |
          shopt -s nullglob # Make glob patterns that match no files expand to a null string
          if [ ! -f "${{ github.workspace }}/gh-pages/benchmarks/history/plot-data.json" ]; then
            echo "No plot data found"
            tarballs=(${{ github.workspace }}/gh-pages/benchmarks/history/*.tar.gz)
            if (( ${#tarballs[@]} )); then
              cat "${tarballs[@]}" | tar -xvzf - -i
            else
              echo "No tarballs found for extraction."
            fi
          fi
          shopt -u nullglob # Disable nullglob option
        working-directory: ${{ github.workspace }}/ci-workflows
      # Saves the plot data to be deployed
      - name: Generate historical performance plot
        run: |
          cp ${{ github.workspace }}/fibonacci-${{ env.COMMIT }}.json .
          cargo run
          mv *.png ${{ github.workspace }}
          mkdir -p ${{ github.workspace }}/history
          mv -f plot-data.json ${{ github.workspace }}/history
        working-directory: ${{ github.workspace }}/ci-workflows
      # TODO: Prettify labels for easier viewing
      # Compress the benchmark file and metadata for later analysis
      - name: Compress artifacts
        run: |
          echo $LABELS > labels.md
          tar -cvzf fibonacci-${{ env.COMMIT }}.tar.gz Cargo.lock fibonacci-${{ env.COMMIT }}.json labels.md
          mv -f fibonacci-${{ env.COMMIT }}.tar.gz history
        working-directory: ${{ github.workspace }}
      # TODO: Arguably the HTML template should be a pre-requisite
      - name: Prepare HTML plots page
        run: |
          if [[ ! -f plots.html ]]; then
            html=$(cat << EOF
          <!DOCTYPE html>
          <html>
          <head>
          <style>
          img {
            width: 100%;
          }
          </style>
          </head>
          <body>
          </body>
          </html>
          EOF
          )
            echo "$html" > plots.html
          fi

          shopt -s nullglob  # Prevent errors if no matching files are found

          for FILE in `ls *.png | sort -g`; do
             if [[ -f $FILE ]]; then # Check if it's a regular file
                 IMAGE="<img src=\"$FILE\" alt=\"Benchmark history plot for $FILE\" style=\"width:1000px;height:1000px;\"/>"
                 echo $IMAGE
                 sed -i "/<\/body>/i\\$IMAGE" plots.html
             fi
          done

          mv -f *.png plots.html history
      - name: Deploy latest benchmark report
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./target/criterion
          destination_dir: benchmarks/criterion
      - name: Deploy benchmark history
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./history
          destination_dir: benchmarks/history
          keep_files: true
