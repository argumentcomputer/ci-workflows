# Prerequisites
# - Self-hosted Nvidia GPU runner with CUDA enabled
# - Runner attached in caller repo with `gpu-ci` label
# - `cuda` and `opencl` Cargo features
name: GPU CI Tests 

on:
  # We expect dependents to call this on `merge_group` and conditionally run with
  # if: github.event_name != 'pull_request' || github.event.action == 'enqueued'
  workflow_call:
    inputs:
      opencl:
        required: false
        type: boolean
        default: false
      # comma-separated list of features to run in addition to `cuda`/`opencl`
      features:
        required: false
        default: ""
        type: string

jobs:
  cuda:
    name: Rust tests on CUDA
    runs-on: [self-hosted, gpu-ci]
    steps:
      - uses: actions/checkout@v4
        with:
          repository: lurk-lab/ci-workflows
      - uses: ./.github/actions/gpu-setup
        with:
          gpu-framework: 'cuda'
      - uses: ./.github/actions/ci-env
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - uses: dtolnay/rust-toolchain@stable
      - uses: taiki-e/install-action@nextest
      - uses: Swatinem/rust-cache@v2
      - name: CUDA tests
        run: |
          cargo nextest run --profile ci --cargo-profile dev-ci --features "cuda,${{ inputs.features }}"

  opencl:
    name: Rust tests on OpenCL
    if: ${{ inputs.opencl }}
    runs-on: [self-hosted, gpu-ci]
    steps:
      - uses: actions/checkout@v4
        with:
          repository: lurk-lab/ci-workflows
      - uses: ./.github/actions/gpu-setup
        with:
          gpu-framework: 'opencl'
      - uses: ./.github/actions/ci-env
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - uses: dtolnay/rust-toolchain@stable
      - uses: taiki-e/install-action@nextest
      - uses: Swatinem/rust-cache@v2
      - name: OpenCL tests
        run: |
          cargo nextest run --profile ci --cargo-profile dev-ci --features "cuda,opencl,${{ inputs.features }}"
