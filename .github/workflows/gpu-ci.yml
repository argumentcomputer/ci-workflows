# Sets env vars based on GPU platform
# Prerequisites
# - Self-hosted Nvidia GPU runner with `gpu-ci` tag in caller repo
# - `cuda` and `opencl` Cargo features
# - `nextest.toml` `ci` profile and `Cargo.toml` `dev-ci` profile
name: GPU CI Tests 

on:
  workflow_call:

jobs:
  cuda:
    name: Rust tests on CUDA
    runs-on: [self-hosted, gpu-ci]
    steps:
      - uses: actions/checkout@v4
        with:
          repository: lurk-lab/ci-workflows
      - uses: ./.github/actions/gpu-setup
        with:
          gpu-framework: 'cuda'
      - uses: ./.github/actions/ci-env
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - uses: dtolnay/rust-toolchain@stable
      - uses: taiki-e/install-action@nextest
      - uses: Swatinem/rust-cache@v2
      - name: CUDA tests
        run: |
          cargo nextest run --profile ci --cargo-profile dev-ci --features cuda

  opencl:
    name: Rust tests on OpenCL
    runs-on: [self-hosted, gpu-ci]
    steps:
      - uses: actions/checkout@v4
        with:
          repository: lurk-lab/ci-workflows
      - uses: ./.github/actions/gpu-setup
        with:
          gpu-framework: 'opencl'
      - uses: ./.github/actions/ci-env
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - uses: dtolnay/rust-toolchain@stable
      - uses: taiki-e/install-action@nextest
      - uses: Swatinem/rust-cache@v2
      - name: OpenCL tests
        run: |
          cargo nextest run --profile ci --cargo-profile dev-ci --features cuda,opencl
